{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbyO5znN++Hclnhkob5om3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditijain-11/Breast-Cancer-Predicition/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1QMAHJEjtU1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score as accuracy\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    #Input: X - features of a trainset\n",
        "    #       y - labels of a trainset\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "        self.no_of_classes = np.max(self.y_train) + 1\n",
        "\n",
        "\n",
        "    #This is our function to calculate all nodes/samples in our radius\n",
        "    def euclidianDistance(self, Xtest, Xtrain):\n",
        "        return np.sqrt(np.sum(np.power((Xtest - Xtrain), 2)))\n",
        "\n",
        "\n",
        "    #our main function is predict\n",
        "    #All calculation is done by using our test or new samples\n",
        "    #There are 4 steps to be performed:\n",
        "    # 1. calculate Prior probability. Ex. P(A) = No_of_elements_of_one_class / total_no_of_samples\n",
        "    # 2. calculate Margin probability P(X) = No_of_elements_in_radius / total_no_of_samples\n",
        "    # 3. calculate Likeliyhood (P(X|A) = No_of_elements_of_current_class / total_no_of_samples\n",
        "    # 4. calculate Posterior probability: P(A|X) = (P(X|A) * P(A)) / P(X)\n",
        "    # NOTE: Do these steps for all clases in dataset!\n",
        "    #\n",
        "    #Inputs: X - test dataset\n",
        "    #       radius - this parameter is how big circle is going to be around our new datapoint, default = 2\n",
        "    def predict(self, X, radius=0.4):\n",
        "        pred = []\n",
        "\n",
        "#         number of malignant and benign elements in member_of_class\n",
        "        members_of_class = []\n",
        "        for i in range(self.no_of_classes):\n",
        "            counter = 0\n",
        "            print(i)\n",
        "            for j in range(len(self.y_train)):\n",
        "                if self.y_train[j] == i:\n",
        "                    counter += 1\n",
        "            members_of_class.append(counter)\n",
        "        print(members_of_class)\n",
        "\n",
        "        #prediction starts\n",
        "        for t in range(len(X)):\n",
        "            #Creating empty list for every class probability\n",
        "            prob_of_classes = []\n",
        "#            for malignant and benign\n",
        "            for i in range(self.no_of_classes):\n",
        "\n",
        "                #1. step > Prior probability P(class) = no_of_elements_of_that_class/total_no_of_elements\n",
        "                prior_prob = members_of_class[i]/len(self.y_train)\n",
        "\n",
        "                #2. step > Margin probability P(X) = no_of_elements_in_radius/total_no_of_elements\n",
        "                #NOTE: In the same loop collecting infromation for 3. step as well\n",
        "\n",
        "                inRadius = 0\n",
        "                #counter for how many points are from the current class in circle\n",
        "                inRadius_current_class = 0\n",
        "\n",
        "#                 finding all points inside the given radius circle\n",
        "\n",
        "                for j in range(len(self.X_train)):\n",
        "                    if self.euclidianDistance(X[t], self.X_train[j]) < radius:\n",
        "                        inRadius += 1\n",
        "                        if self.y_train[j] == i:\n",
        "                            inRadius_current_class += 1\n",
        "\n",
        "                #finding margin probability\n",
        "                margin_prob = inRadius/len(self.X_train)\n",
        "                if margin_prob == 0:\n",
        "                    margin_prob = 0.0000000000000000000000000000000000000000000000001\n",
        "\n",
        "                #3. step > Likelihood P(X|current_class) = no_of_elements_in_circle_of_current_class/total_no_of_elements\n",
        "                likelihood = inRadius_current_class/len(self.X_train)\n",
        "\n",
        "#                 #4. step > Posterial Probability > formula from Bayes theorem: P(current_class | X) = (likelihood*prior_prob)/margin_prob\n",
        "                post_prob = (likelihood * prior_prob)/margin_prob\n",
        "                prob_of_classes.append(post_prob)\n",
        "\n",
        "            #Getting index of the biggest element (class with the biggest probability)\n",
        "            pred.append(np.argmax(prob_of_classes))\n",
        "\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "z629n14qkwKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "#     list of all features from the data\n",
        "list_of_columns = list(df.columns)\n",
        "\n",
        "#     list of features for my model\n",
        "prediction_vars = ['diagnosis','radius_mean','perimeter_mean','area_mean','compactness_mean','concavity_mean','concave points_mean',\n",
        "                   'radius_se','area_se' ]\n",
        "\n",
        "# removing non- required features\n",
        "for ele in list_of_columns:\n",
        "    if ele in prediction_vars:\n",
        "        list_of_columns.remove(ele)\n",
        "\n",
        "df = df.drop(columns = list_of_columns ,axis=1)\n",
        "df['diagnosis'] = df['diagnosis'].map({'M':1, 'B':0})\n",
        "\n",
        "#     assigning features to x\n",
        "#     assigning labels to y\n",
        "X = df.iloc[:,1:].values\n",
        "y = df.iloc[:,0:1].values\n",
        "\n",
        "#     splitting data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "    #Testing my Naive Bayes Classifier\n",
        "NB = NaiveBayesClassifier()\n",
        "NB.fit(X_train, y_train)\n",
        "\n",
        "y_pred = NB.predict(X_test, radius=8)\n",
        "\n",
        "#     sklearn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "NB_sk = GaussianNB()\n",
        "NB_sk.fit(X_train, y_train)\n",
        "\n",
        "sk_pred = NB_sk.predict(X_test)\n",
        "print(\"Accuracy for my Naive Bayes Classifier: \", accuracy(y_test, y_pred)*100, \"%\")\n",
        "print(\"Accuracy for sklearn Naive Bayes Classifier: \",accuracy(y_test, sk_pred)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qclkq0uZk3Vb",
        "outputId": "6569b117-41ba-47c1-e352-8b55d20f6838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "[267, 159]\n",
            "Accuracy for my Naive Bayes Classifier:  85.3146853146853 %\n",
            "Accuracy for sklearn Naive Bayes Classifier:  90.20979020979021 %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explainer Object"
      ],
      "metadata": {
        "id": "KoSO1L4Tln1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxCDOlQNmaxQ",
        "outputId": "ba67f0a2-2d70-4150-d560-f4b8b97b1e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lime import lime_tabular\n",
        "\n",
        "explainer_lime = lime_tabular.LimeTabularExplainer(X_train,feature_names=prediction_vars,verbose=True,mode='classification')"
      ],
      "metadata": {
        "id": "_7ijYiaalmzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 10\n",
        "k=5\n",
        "# Calling the explain_instance method by passing in the:\n",
        "#    1) ith test vector\n",
        "#    2) prediction function used by our prediction model('reg' in this case)\n",
        "#    3) the top features which we want to see, denoted by k\n",
        "\n",
        "exp_lime = explainer_lime.explain_instance(X_test[i], reg.predict, num_features=k)\n",
        "\n",
        "# Finally visualizing the explanations\n",
        "exp_lime.show_in_notebook()\n"
      ],
      "metadata": {
        "id": "MDGFfktHmz1Q",
        "outputId": "f3a5cceb-08c7-419b-9078-7aed33cad627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-b35769c9ea9e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#    3) the top features which we want to see, denoted by k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mexp_lime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer_lime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Finally visualizing the explanations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_tabular.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 raise NotImplementedError(\"LIME does not currently support \"\n\u001b[0m\u001b[1;32m    362\u001b[0m                                           \u001b[0;34m\"classifier models without probability \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                                           \u001b[0;34m\"scores. If this conflicts with your \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: LIME does not currently support classifier models without probability scores. If this conflicts with your use case, please let us know: https://github.com/datascienceinc/lime/issues/16"
          ]
        }
      ]
    }
  ]
}